# RAG Chatbot

An intelligent chatbot developed for a project in Instituto PolitÃ©cnico de Viana do Castelo (IPVC) that uses **Retrieval-Augmented Generation (RAG)** to process and answer questions based on PDF documents.

## Table of Contents

- [Features](#-features)
- [Technologies Used](#-technologies-used)
- [System Architecture](#-system-architecture)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [How to Use](#-how-to-use)
- [Project Structure](#-project-structure)
- [API Endpoints](#-api-endpoints)
- [Contributing](#-contributing)
- [License](#-license)

## Features

- ğŸ” **PDF Processing**: Upload and automatic processing of PDF documents
- ğŸ§  **RAG (Retrieval-Augmented Generation)**: Accurate responses based on PDF content
- ğŸ¤– **Multiple Models**: Support for OpenAI GPT and Ollama (local LLM)
- ğŸ“Š **Intuitive Interface**: Modern web interface with Bootstrap
- ğŸ”— **Source Citations**: Shows page and file sources of responses
- ğŸ“± **Responsive**: Works on desktop and mobile devices
- âš¡ **Real-time Processing**: Fast and efficient responses

## Technologies Used

### Backend
- **Python 3.8+**
- **Flask** - Web framework
- **LangChain** - Framework for LLM applications
- **FAISS** - Vector search library
- **PyPDF2** - PDF processing

### AI Models
- **OpenAI GPT** - OpenAI language model
- **Ollama** - Local LLM for privacy

### Frontend
- **HTML5/CSS3**
- **Bootstrap 5** - CSS framework
- **JavaScript** - Interactivity

### Storage
- **FAISS Index** - Vector indices for semantic search
- **Pickle** - Data serialization

## System Architecture

The system follows a modular architecture with the following main components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend       â”‚    â”‚   AI Models     â”‚
â”‚   (Flask UI)    â”‚â—„â”€â”€â–ºâ”‚   (Flask API)    â”‚â—„â”€â”€â–ºâ”‚  (OpenAI/Ollama)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Vector Store    â”‚
                       â”‚   (FAISS)        â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **PDF Upload** â†’ Text extraction â†’ Chunking
2. **Embedding** â†’ Vector creation â†’ FAISS storage
3. **User question** â†’ Question embedding â†’ Semantic search
4. **Relevant context** â†’ Answer generation â†’ Return to user

## Installation

### Prerequisites

- Python 3.8 or higher
- pip (Python package manager)
- Git

### Installation Steps

1. **Clone the repository**
```bash
git clone https://github.com/your-username/CHATBOT_WITH_RAG.git
cd CHATBOT_WITH_RAG
```

2. **Create a virtual environment**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment variables**
```bash
# Create a .env file in the project root
touch .env
```

## Configuration

### 1. Environment Variables

Create a `.env` file in the project root with the following variables:

```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Chunking Configuration
CHUNK_SIZE_OPENAI=10000
CHUNK_OVERLAP_OPENAI=1000
CHUNK_SIZE_OLLAMA=1200
CHUNK_OVERLAP_OLLAMA=200
```

### 2. Ollama Configuration (Optional)

If you want to use Ollama for local processing:

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Download a model (example)
ollama pull llama2
```

### 3. Directory Structure

The project will automatically create the following directories:
- `data/raw_pdfs/` - Uploaded PDFs
- `data/faiss_index_openai/` - OpenAI vector indices
- `data/faiss_index_ollama/` - Ollama vector indices
- `logs/` - Log files

## How to Use

### 1. Start the Server

```bash
python app.py
```

The server will be available at: `http://localhost:5000`

### 2. Web Interface

1. **Upload PDFs**: Use the sidebar to load PDF documents
2. **Configure RAG**: Choose the embedding model and enable RAG
3. **Process PDFs**: Click "Load RAG with PDF" to process documents
4. **Ask Questions**: Use the "Chatbot" tab to interact with the system

### 3. Main Features

#### Upload and Processing
- Support for multiple simultaneous PDFs
- Automatic text processing
- Vector index creation

#### Intelligent Chat
- Responses based on PDF content
- Source citations (file and page)
- Support for questions in Portuguese

#### PDF Visualization
- Integrated document viewing
- File downloads
- List of uploaded PDFs

## Project Structure

```
CHATBOT_WITH_RAG/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ .gitignore            # Git ignored files
â”œâ”€â”€ README.md             # This file
â”‚
â”œâ”€â”€ config/               # Configuration
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ data/                 # Data and indices
â”‚   â”œâ”€â”€ raw_pdfs/         # Uploaded PDFs
â”‚   â”œâ”€â”€ faiss_index_openai/   # OpenAI indices
â”‚   â””â”€â”€ faiss_index_ollama/   # Ollama indices
â”‚
â”œâ”€â”€ models/               # AI models
â”‚   â”œâ”€â”€ embeddings/       # Embedding models
â”‚   â”œâ”€â”€ llms/            # Language models
â”‚   â””â”€â”€ retriever/       # Retrieval system
â”‚
â”œâ”€â”€ templates/            # HTML templates
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ view_pdf.html
â”‚
â”œâ”€â”€ static/              # Static files
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ images/          # Images and graphics
â”‚
â”œâ”€â”€ utils/               # Utilities
â”‚   â”œâ”€â”€ pdf_processing.py
â”‚   â”œâ”€â”€ text_processing.py
â”‚   â””â”€â”€ vector_store.py
â”‚
â””â”€â”€ tests/               # Tests
    â”œâ”€â”€ test_pdf_processing.py
    â””â”€â”€ test_vector_store.py
```

## API Endpoints

### Upload and Processing
- `POST /upload` - Upload PDFs
- `POST /process_pdfs` - Process PDFs for RAG
- `GET /list_pdfs` - List uploaded PDFs

### Chat and Visualization
- `POST /chat` - Send message to chatbot
- `GET /view/<filename>` - View PDF
- `GET /download/<filename>` - Download PDF


## Tests

Run unit tests:

```bash
# Run all tests
pytest

# Run specific test
pytest tests/test_pdf_processing.py

# Run with coverage
pytest --cov=.
```

## System Images

The project includes diagrams that illustrate the system's operation:

![System Architecture](static/images/graph1.png)
*General system architecture*

![Data Flow](static/images/graph2.png)
*Data processing flow*

![PDF Processing](static/images/graph3.png)
*PDF document processing*

![RAG Integration](static/images/graph4.png)
*RAG integration with PDFs*

## Contributing

Contributions are welcome! To contribute:

1. Fork the project
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Code Standards

- Use Python 3.8+
- Follow PEP 8 for code style
- Add tests for new features
- Document important functions and classes

## License

This project is under the MIT license. See the `LICENSE` file for more details.



